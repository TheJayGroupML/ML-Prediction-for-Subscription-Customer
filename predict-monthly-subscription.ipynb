{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "#### Predict if Subscription Customer or Regular Customer",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\nimport numpy as np\nfrom sklearn import preprocessing\n\ndata \u003d \"path/to/csv/data.csv\"\nraw_csv_data \u003d np.loadtxt(\u0027data\u0027, delimiter \u003d\u0027,\u0027)\nunscaled_inputs_all \u003d raw_csv_data[:,1:-1]\ntargets_all \u003d raw_csv_data[:,-1]\n\nnum_one_targets \u003d int(np.sum(targets_all))\n\nzero_targets_counter \u003d 0\nindices_to_remove\u003d[]\n\nfor i in range(targets_all.shape[0]): #targets_all.shape[0]: returns the number of rows in the dataset\n    if targets_all[i] \u003d\u003d 0:\n        zero_targets_counter +\u003d 1 #ztc\u003dztc+1 \n        if zero_targets_counter \u003e num_one_targets:\n            indices_to_remove.append(i)\n        \nunscaled_inputs_equal_priors \u003d np.delete(unscaled_inputs_all, indices_to_remove, axis\u003d0)\n\ntargets_equal_priors \u003d np.delete(targets_all, indices_to_remove, axis\u003d0)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "#### Standardize the inputs: scaling"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "scaled_inputs \u003d preprocessing.scale(unscaled_inputs_equal_priors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "#### Shuffle the data:"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "shuffled_indices \u003d np.arange(scaled_inputs.shape[0]) #gives indices numbers from 0 to 4473 \u003d 4474 numbers which is the range. (scaled_inputs.shape[0] \u003d 4474) \n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "#use the shuffled indices to shuffle the inputs and targets\n",
        "shuffled_inputs \u003d scaled_inputs[shuffled_indices]\n",
        "shuffled_targets \u003d targets_equal_priors[shuffled_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "#### Split the dataset: train, validation, and test"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1815.0 3579 0.5071248952221291\n",
            "225.0 447 0.5033557046979866\n",
            "197.0 448 0.43973214285714285\n"
          ]
        }
      ],
      "source": "\nsamples_count \u003d shuffled_inputs.shape[0]\n\ntrain_samples_count \u003d int(0.8 * samples_count)\nvalidation_samples_count \u003d int(0.1 * samples_count)\ntest_samples_count \u003d samples_count - train_samples_count - validation_samples_count\n\ntrain_inputs \u003d shuffled_inputs[:train_samples_count]\ntrain_targets \u003d shuffled_targets[:train_samples_count]\n\nvalidation_inputs \u003d shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\nvalidation_targets \u003d shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n\ntest_inputs \u003d shuffled_inputs[train_samples_count + validation_samples_count:]\ntest_targets \u003d shuffled_targets[train_samples_count + validation_samples_count:]\n\nprint(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\nprint(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\nprint(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)\n\nnp.savez(\u0027YOUR_DATA_data_train\u0027, inputs\u003dtrain_inputs, targets \u003d train_targets)\nnp.savez(\u0027YOUR_DATA_data_validation\u0027, inputs\u003dvalidation_inputs, targets\u003dvalidation_targets)\nnp.savez(\u0027YOUR_DATA_data_test\u0027, inputs \u003d test_inputs, targets\u003d test_targets)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": "#### Create a class that handles batching"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "class get_data():\n    def __init__(self, dataset, batch_size\u003dNone):\n        npz \u003d np.load(\"YOUR_DATA_data_{0}.npz\".format(dataset))\n        self.inputs, self.targets \u003d npz[\u0027inputs\u0027].astype(np.float), npz[\u0027targets\u0027].astype(np.int)\n        if batch_size is None:\n            self.batch_size \u003d self.inputs.shape[0]\n        else:\n            self.batch_size \u003d batch_size\n        self.curr_batch \u003d 0\n        self.batch_count \u003d self.inputs.shape [0] // self.batch_size\n    \n    def __next__(self):\n        if self.curr_batch\u003e\u003dself.batch_count:\n            self.curr_batch \u003d 0\n            raise StopIteration()\n        batch_slice \u003d slice(self.curr_batch * self.batch_size, (self.curr_batch + 1) * self.batch_size)\n        inputs_batch \u003d self.inputs[batch_slice]\n        target_batch \u003d self.targets[batch_slice]\n        self.curr_batch +\u003d1\n        classes_num \u003d 2\n        targets_one_hot \u003d np.zeros((target_batch.shape[0], classes_num))\n        targets_one_hot[range(target_batch.shape[0]), target_batch] \u003d 1\n        return inputs_batch, targets_one_hot\n    \n    def __iter__(self):\n        return self\n    \n"
    },
    {
      "cell_type": "markdown",
      "source": "#### Create the Machine Learning Algorithm ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\nimport tensorflow as tf\n\ninput_size \u003d 10 \noutput_size \u003d 2 \nhidden_layer_size \u003d 200\n\n\ntf.reset_default_graph()\n\ninputs \u003d tf.placeholder(tf.float32, [None, input_size])\ntargets \u003d tf.placeholder(tf.int32, [None, output_size])\n\nweights_1 \u003d tf.get_variable(\u0027weights_1\u0027, [input_size, hidden_layer_size])\nbiases_1 \u003d tf.get_variable(\u0027biases_1\u0027, [hidden_layer_size])\noutputs_1 \u003d tf.nn.relu(tf.matmul(inputs, weights_1) + biases_1)\n\nweights_2 \u003d tf.get_variable(\"weights_2\", [hidden_layer_size, hidden_layer_size])\nbiases_2 \u003d tf.get_variable(\"biases_2\", [hidden_layer_size])\noutputs_2 \u003d tf.nn.relu(tf.matmul(outputs_1, weights_2) + biases_2)\n\nweights_3 \u003d tf.get_variable(\"weights_3\", [hidden_layer_size, output_size])\nbiases_3 \u003d tf.get_variable(\"biases_3\", [output_size])\n\n\noutputs \u003d tf.matmul(outputs_2, weights_3) + biases_3\n\nloss \u003d tf.nn.softmax_cross_entropy_with_logits(logits \u003d outputs, labels \u003d targets)\nmean_loss \u003d tf.reduce_mean(loss)\n\n\nout_equals_target \u003d tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1))\naccuracy \u003d tf.reduce_mean(tf.cast(out_equals_target, tf.float32))\n\noptimize \u003d tf.train.AdamOptimizer(learning_rate \u003d 0.003).minimize(mean_loss)\n\nsess\u003d tf.InteractiveSession()\n\ninitializer \u003d tf.global_variables_initializer()\nsess.run(initializer)\n\nbatch_size\u003d500\nmax_epochs \u003d50\nprev_validation_loss \u003d 9999999.\n\ntrain_data \u003d get_data(\u0027train\u0027, batch_size)\nvalidation_data \u003d get_data(\u0027validation\u0027)\n\n#optimize the algorithm: create for loop for epochs:\nfor epoch_counter in range(max_epochs):\n    curr_epoch_loss\u003d0.\n    for input_batch, target_batch in train_data: #iterate over the training data\n        _, batch_loss \u003d sess.run([optimize,mean_loss],\n                feed_dict \u003d {inputs: input_batch, targets: target_batch})\n        curr_epoch_loss +\u003dbatch_loss #record the batch loss into the current loss\n    curr_epoch_loss /\u003dtrain_data.batch_count #find the mean curr_epoch_loss\n    validation_loss \u003d 0.\n    validation_accuracy \u003d 0.\n    for input_batch, target_batch in validation_data: #use the same logic of the code to forward propagate the validation set \n        validation_loss, validation_accuracy \u003d sess.run([mean_loss, accuracy],\n            feed_dict \u003d {inputs: input_batch, targets: target_batch})\n    print(\u0027Epoch \u0027+str(epoch_counter+1)+\n          \u0027. Training loss: \u0027+\u0027{0:.3f}\u0027.format(curr_epoch_loss)+\n          \u0027. Validation loss: \u0027+\u0027{0:.3f}\u0027.format(validation_loss)+\n          \u0027. Validation accuracy: \u0027+\u0027{0:.2f}\u0027.format(validation_accuracy * 100.)+\u0027%\u0027)\n    if validation_loss \u003e prev_validation_loss:\n        break\n    prev_validation_loss \u003d validation_loss\n        \nprint(\u0027End of training\u0027)\n    \n    \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "#### Test the Model:\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:82.59%\n"
          ]
        }
      ],
      "source": "test_data \u003d get_data(\u0027test\u0027)\n\nfor input_batch, target_batch in test_data: # we need the forwardpropagate as we did in the validation. cpy and past the validation forward propagate change the names and change the second line \n        test_accuracy \u003d sess.run([accuracy],\n            feed_dict \u003d {inputs: input_batch, targets: target_batch})\n        \ntest_accuracy_percent \u003d test_accuracy[0] *100.\n\nprint(\u0027test accuracy:\u0027 + \u0027{0:.2f}\u0027.format(test_accuracy_percent) + \u0027%\u0027)\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}